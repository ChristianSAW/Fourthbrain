{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.5_COVID_19_Predictions_for_Chicago.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IN_8JURhTik"
      },
      "source": [
        "## This exercise performs hands-on regression on COVID-19 data for Chicago to predict the number of infections\n",
        "This is an adapted version from source: https://towardsdatascience.com/understanding-regression-using-covid-19-dataset-detailed-analysis-be7e319e3a50\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0AOSpPBhgcX"
      },
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXD4ODuFhrrB"
      },
      "source": [
        "# Read the Data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/Ayushijain09/Regression-on-COVID-dataset/master/COVID-19_Daily_Testing.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO9WRyI_iaYE"
      },
      "source": [
        "# Display the data\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKX6E9Vpawfo"
      },
      "source": [
        "The presence of commas in some of the numeric columns above (all columns from 2 on, using Python's indexing convention) suggests that some of them are represented as strings rather than integers. Let's check if that's true. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF9LnDzcXO_9"
      },
      "source": [
        "column_contains_strings = data.iloc[:,2:].applymap(type).eq(str).any()\n",
        "column_contains_strings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA3j9G3QdXe2"
      },
      "source": [
        "# Exercise: Data Cleaning\n",
        "\n",
        "Ideally, every value in the Pandas `Series` above should be `False` (the column names are `Series` indices rather than values). We'll have to convert the values of the columns from 2 on to integers if they're currently represented as strings. First, we'll have to eliminate the commas in the ostensibly numeric columns. You might find the following methods useful: [pd.Series.str.replace()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html), [pd.to_numeric()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html), "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3yrmbhiipfH"
      },
      "source": [
        "### BEGIN CODE HERE ###\n",
        "# Iterate over the columns in data\n",
        "for i in range(None):\n",
        "  # Carry out the replacement and conversion if i is at least 2 and the column contains strings\n",
        "  # Don't forget that column_contains_strings ignores the 0th and 1st columns of data \n",
        "  if None:\n",
        "    # Eliminate any commas in the number strings\n",
        "    data.iloc[:,i]=None\n",
        "    # Convert the string column to a numeric column\n",
        "    data.iloc[:,i]=None\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8OqlTBfi2zY"
      },
      "source": [
        "Verify that only the `Date` and `Day` columns contain strings now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3AJ5ngCivCY"
      },
      "source": [
        "data.applymap(type).eq(str).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25SDqMS9lWKt"
      },
      "source": [
        "### Extract the first 10 numeric columns. Inspect visually how those features correlate with each other, print out some summary statistics, and display the first few rows of the reduced numeric dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47uTxL-xi7Z8"
      },
      "source": [
        "# Plot pairwise dependence of features, select columns 2-12 only for example\n",
        "data_numeric = data.iloc[:,2:12]\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.pairplot(data_numeric)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8qiWEEVl4o7"
      },
      "source": [
        "print(data_numeric.shape)\n",
        "data_numeric.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTCwIEr0mQZN"
      },
      "source": [
        "data_numeric.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmFYjkGj87hf"
      },
      "source": [
        "### Variance Inflation Factor (VIF)\n",
        "\n",
        "The pair plots above suggest that many of the features above correlate strongly with each other. Such multi-linearity can cause problems with model convergence. In your next exercise, you will identify which features are most responsible for these issues. To do so, you will calculate the variance inflation factor (VIF) for each feature. If a feature has VIF>10, it has high multi-linearity.\n",
        "\n",
        "A feature $X_j$ in an array of features $X$ has a VIF given by \n",
        "\n",
        "$$\\textrm{VIF}_j = \\frac{1}{1 - R^2_j}.$$\n",
        "\n",
        "In turn, the coefficient of determination $R^2_i$ for the $j$th feature of $X$ is given by \n",
        "\n",
        "$$R^2_j = 1 - \\frac{\\sum_i (X_{ij} - \\hat{X}_{ij})^2}{\\sum_i (X_{ij} - \\overline{X}_{j})^2}.$$\n",
        "\n",
        "In the formula above, $i$ is the row index of $X$, $j$ is the column index, $\\hat{X}_{ij}$ is the predicted value of $X_{ij}$ obtained by performing linear regression with $X_j$ as the target column and all of the other columns of $X$ as features, and $\\overline{X}_{j})$ is the mean value of all elements in $X_j$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLR0otf9kwY5"
      },
      "source": [
        "First, we need a function for computing VIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_HIPlCC0v1"
      },
      "source": [
        "from statsmodels.regression.linear_model import OLS\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "def variance_inflation_factors(exog_df):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    exog_df : dataframe, (nobs, k_vars)\n",
        "        design matrix with all explanatory variables, as for example used in\n",
        "        regression.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    vif : Series\n",
        "        variance inflation factors\n",
        "    '''\n",
        "    exog_df = add_constant(exog_df)\n",
        "    vifs = pd.Series(\n",
        "        [1 / (1. - OLS(exog_df[col].values, \n",
        "                       exog_df.loc[:, exog_df.columns != col].values).fit().rsquared) \n",
        "         for col in exog_df],\n",
        "        index=exog_df.columns,\n",
        "        name='VIF'\n",
        "    )\n",
        "    return vifs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp4QS1RYHlDI"
      },
      "source": [
        "### Calculate VIF for a single column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK-iwsndJ2ec"
      },
      "source": [
        "In the following cell, you see how to pass a single column of numeric data into the `variance_inflation_factors()` function to determine its colinearity. By definition, a given feature is perfectly colinear with itself, with a VIF of 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9IAQKLxDMrG",
        "outputId": "d73d3dcd-ee08-4aaf-d776-ac5fa932f068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "variance_inflation_factors(data_numeric.iloc[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "const    2.57394\n",
              "Tests    1.00000\n",
              "Name: VIF, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fni8pf7hJ5dA"
      },
      "source": [
        "In case you had forgotten from the summary statistics above, the 0th column of the `data_numeric` `DataFrame` is named `'Tests'`, which the `Series` output by the most recent call to `variance_inflation_factors()` reflects. Notice also the VIF score for the `const` column which we added locally, within the scope of `variance_inflation_factors()`. For our purposes, we can ignore it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKL7JHU6LvJC"
      },
      "source": [
        "### Exercise: Use VIF to detect highly colinear features\n",
        "\n",
        "First, pass the entire reduced numeric dataset into the VIF function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEtYt4lAnJwZ"
      },
      "source": [
        "### BEGIN CODE HERE ###\n",
        "None\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap2IjyqevhBj"
      },
      "source": [
        "If you saw any infinite values above, don't panic just yet. Call the VIF function again, but this time, don't pass in the columns with finite VIF values above 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNXZgeylpNAL"
      },
      "source": [
        "### BEGIN CODE HERE ###\n",
        "None\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH9oeAjTw48q"
      },
      "source": [
        "Did you still get several infinite VIF values? That seems a bit disconcerting. Just in case, try passing the first 2 columns from the subset above into the VIF function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "684KofbxpThy"
      },
      "source": [
        "### BEGIN CODE HERE ###\n",
        "None\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_dyaKfPxZUx"
      },
      "source": [
        "Aha! This should yield a VIF well below 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoKppZFpymIm"
      },
      "source": [
        "### Exercise: Extract the feature and target from the dataset\n",
        "\n",
        "By now, we're down to 2 numeric columns from the original dataset. The goal is to predict the number of COVID-19 cases, so one column is a feature, and the other is your target. Extract them from the dataset as NumPy arrays. Make sure that each array is 2D, and that its rows correspond to training examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jLhmoMtj-bL"
      },
      "source": [
        "### BEGIN CODE HERE ###\n",
        "# Feature\n",
        "X = None\n",
        "# Target\n",
        "y = None\n",
        "### END CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE42OH32zUoX"
      },
      "source": [
        "### Exercise: Linear Regression\n",
        "\n",
        "Apply linear regression to the feature and target. You might find scikit-learn's [`LinearRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression) class and its methods helpful. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q44ge24akFTl"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Instantiate the linear regression model\n",
        "reg = None\n",
        "# Train the model on the full feature and target arrays\n",
        "# Keep in mind that this is not good practice as a general rule\n",
        "# We're doing so for illustrative purposes only\n",
        "None\n",
        "# Use your newly trained model to compute predicted target values based on the feature values\n",
        "predictions = None\n",
        "### END CODE HERE ###\n",
        "# Visualize your (highly reduced) ground truth data and model\n",
        "print(\"The linear model is: Y = {:.5} + {:.5}X\".format(reg.intercept_[0], reg.coef_[0][0]))\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.scatter(\n",
        "    X,\n",
        "    y,\n",
        "    c='black'\n",
        ")\n",
        "plt.plot(\n",
        "    X,\n",
        "    predictions,\n",
        "    c='blue',\n",
        "    linewidth=2\n",
        ")\n",
        "plt.xlabel(\"Tests\")\n",
        "plt.ylabel(\"Cases\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqEFb5Jw1G7A"
      },
      "source": [
        "### Exercise: Polynomial Regression\n",
        "\n",
        "A number of points in the plot above appear to be quite far off of the predicted line. Let's see if fitting a polynomial to our data produces better results. Polynomial regression isn't very different from linear regression; the prediction function is still linear in the $\\theta$ coefficients which you're attempting to solve. For quadratic regression, you would simply need to add feature columns containing the squares of the values of your original feature columns. The same pattern applies for higher-degree polynomial regression. Choosing too high a degree is not only computationally costly, it's also likely to result in your model overfitting to your training data. Imagine you have a large but finite number of points in an x-y plane. As long as every point has a unique x value, it's possible to find a polynomial which runs through all of your points perfectly. However, in that situation, it's highly unlikely that if you add a new point to the plane, it will land on your curve of best fit. Your model will thus be highly variable, insufficielty generalizable, overfit.\n",
        "\n",
        "Here, we'll see if a 4th-degree polynomial describes the relationship between `X` and `y` better than a line. Fortunately, sklearn.preprocessing provides the [`PolynomialFeatures()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html?highlight=polynomialfeatures#sklearn.preprocessing.PolynomialFeatures) class so we don't have to compute the higher powers of feature columns manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLbdutTxkMgb"
      },
      "source": [
        "### START CODE HERE ###\n",
        "# Instantiate a 4th-degree polynomial features object\n",
        "poly = None\n",
        "# Use that object to generate a transformed X array with higher-degree feature columns\n",
        "X_poly = None\n",
        "# Instantiate a linear regression model\n",
        "lin2 = None\n",
        "# Train the model on the TRANSFORMED feature array and the target array\n",
        "None\n",
        "# Use your newly trained model to compute predicted target values based on the feature values\n",
        "pred = None\n",
        "### END CODE HERE ###\n",
        "# Visualize your (highly reduced) ground truth data and model\n",
        "new_X, new_y = zip(*sorted(zip(X, pred)))\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.scatter(\n",
        "    X,\n",
        "    y,\n",
        "    c='black'\n",
        ")\n",
        "plt.plot(\n",
        "    new_X, new_y,\n",
        "    c='blue'\n",
        ")\n",
        "plt.xlabel(\"Tests\")\n",
        "plt.ylabel(\"Cases\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOOChQu5Cgy"
      },
      "source": [
        "### Compute the MSE for both your linear and polynomial regression models\n",
        "\n",
        "Which performed better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ckc6_ANkclf"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Linear regression error is=\", mean_squared_error(y, predictions, squared=False))\n",
        "print(\"Polynomial regression error is=\", mean_squared_error(new_y, pred, squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2onw9zVKPus"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}